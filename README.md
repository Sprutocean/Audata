# Audata (built on VANA)

# üöÄ WE ARE THE FUEL FOR AUDIO MACHINE LEARNING. 
# What exactly do we do?
Our project leverages Vana technology to create a unique ecosystem where everyone can securely provide the personal audio content staying capable to govern it. The project focuses on the system designed to handle audio files which contain spontaneous speech, often represented as audio messages. That is how the system's scalability is easily achieved - by utilizing pre-existing audio data.

Highly active telegram and WhatsApp users can produce hundreds of audio recordings per week. This results in thousands of recordings per user. Just several thousand participants (providers) can create the database of game-changing size: the resulting array could easily reach hundreds of thousands of minutes of audio material. This will already be enough to fuel revolutionary projects of various kinds.

# üìã A BIT OF THEORY: What is DLP?

# üñ•Ô∏è USAGE EXAMPLES: How you can use what we do?
Scientific research - 

The Challenge:

A team of linguists is researching the evolution of Spanish dialects worldwide. Their goal is to build a sophisticated computational model capable of identifying any dialect represented. Traditional research methods would require contacting and interviewing individuals in numerous communities across all 21 countries, potentially involving hundreds of focus groups to account for regional variations within each country. This is so time and energy and money consuming,

The Solution:

Our platform provides the linguists with access to a geographically representative dataset of audio recordings. To gain access, the team needs to propose their research project to the v3-Data-DAO community and garner sufficient support.If approved, they will not spend any extra money and will only pay for clean and ready-to-use data.

---

AI and neuronets development-

The Challenge:

A game development company needs diverse, high-quality audio data in multiple languages to create more engaging dialogue for the numerous non-player characters (NPCs). Gathering this data traditionally would require the extensive global recruitment and impossible efforts.

The Solution:
By simply requesting access to pre-categorized audio pools (segmented by language, age, occupation, etc.), the company can quickly obtain the diverse audio data needed for NPC voice acting. They can create hundreds of small request to pick up only those datasets that they really need for their character portraits.

# üåü FUTURE: What we are planning to do?



# ü§ù CONTRIBUTING: how you can help us?
First of all, you can contribute to our projects and tools here, on Github. We are tracking the activity around it aalll the time. 
Secondly, you can apply for a position in our team. If you can do something great for the future of audio science, why not to start right now? 
Thridly, you can start a project based on raw data we collect.
